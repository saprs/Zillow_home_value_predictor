{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "A set of helper functions for the Kaggle/Zillow case study for Data Science Dream Job\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def read_in_dataset(dset, verbose=False):\n",
    "    \n",
    "    \"\"\"Read in one of the Zillow datasets (train or properties)\n",
    "\n",
    "    Keyword arguments:\n",
    "    dset -- a string in {properties_2016, properties_2017, train_2016, train_2017}\n",
    "    verbose -- whether or not to print info about the dataset\n",
    "    \n",
    "    Returns:\n",
    "    a pandas dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv('unzipped_data/{0}.csv'.format(dset))\n",
    "    \n",
    "    if verbose:\n",
    "        print('\\n{0:*^80}'.format(' Reading in the {0} dataset '.format(dset)))\n",
    "        print(\"\\nit has {0} rows and {1} columns\".format(*df.shape))\n",
    "        print('\\n{0:*^80}\\n'.format(' It has the following columns '))\n",
    "        print(df.columns)\n",
    "        print('\\n{0:*^80}\\n'.format(' The first 5 rows look like this '))\n",
    "        print(df.head())\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_dataset(train, properties):\n",
    "    \n",
    "    \"\"\"Merge the train and properties datasets. Both need to have a common key `parcelid`\n",
    "\n",
    "    Keyword arguments:\n",
    "    train -- the dataframe of transactions\n",
    "    properties -- the dataframe of properties\n",
    "    \n",
    "    Returns:\n",
    "    a pandas dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    train_data_merged = train.merge(properties, how='left', on='parcelid')\n",
    "    \n",
    "    return train_data_merged\n",
    "\n",
    "\n",
    "\n",
    "def filter_duplicate_parcels(df, random_state=0):\n",
    "    \"\"\"filter the merged train and properties datasets to only include one record per parcel.\n",
    "    \n",
    "    Intended only for use on the training data for building the model\n",
    "\n",
    "    Keyword arguments:\n",
    "    df -- the result of `merge_dataset`\n",
    "    random_state -- the random seed to be passed to the `pandas.DataFrame.sample()` method\n",
    "    \n",
    "    Returns:\n",
    "    a pandas dataframe\n",
    "    \"\"\"\n",
    " \n",
    "    counts_per_parcel = df.groupby('parcelid').size()\n",
    "    more_than_one_sale = df[df.parcelid.isin(counts_per_parcel[counts_per_parcel > 1].index)]\n",
    "    only_one_sale = df[df.parcelid.isin(counts_per_parcel[counts_per_parcel == 1].index)]\n",
    "    reduced_df = more_than_one_sale.sample(frac=1, random_state=random_state).groupby('parcelid').head(1)\n",
    "    reduced_df = pd.concat([only_one_sale, reduced_df])\n",
    "    \n",
    "    return reduced_df\n",
    "\n",
    "\n",
    "def get_data(dset):\n",
    "    \n",
    "    \"\"\"Create the training dataset (2016) or the test dataset (2017)\n",
    "\n",
    "    Keyword arguments:\n",
    "    dset -- a string in {train, test}\n",
    "    \n",
    "    Returns:\n",
    "    a tuple of pandas dataframe (X) and pandas series (y)\n",
    "    \"\"\"\n",
    "    \n",
    "    year = {'train':2016, 'test':2017}[dset]\n",
    "    \n",
    "    train = read_in_dataset('train_{0}'.format(year))\n",
    "    properties = read_in_dataset('properties_{0}'.format(year))\n",
    "    merged = merge_dataset(train, properties)\n",
    "    \n",
    "    if dset == 'train':\n",
    "        merged = filter_duplicate_parcels(merged)\n",
    "    \n",
    "    y = merged.pop('logerror')\n",
    "    return merged, y\n",
    "\n",
    "def mean_abs_error(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
